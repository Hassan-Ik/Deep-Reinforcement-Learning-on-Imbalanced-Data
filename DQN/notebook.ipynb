{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hassa\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hassa\\OneDrive\\Desktop\\AI Degree\\Knowledge Representation and Reasonins\\Deep-Reinforcement-Learning-on-Imbalanced-Data\\DQN\\agent.py:11: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from collections import deque\n",
    "import random\n",
    "from qnetwork import DQNetwork\n",
    "from dataset import CustomImageDataset\n",
    "from agent import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_csv(folder_path: str, file_path: str):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = shuffle(df, random_state=42)\n",
    "    df[\"filepath\"] = folder_path + df[\"image_id\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../digit-recognizer/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = reading_csv(\"../cassava-leaf-disease-classification/train_images/\", \"../cassava-leaf-disease-classification/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_some_labels(df, label):\n",
    "    label_ = df[df['label'] == label]\n",
    "    n_to_drop = label_.shape[0]//3\n",
    "    index_to_drop = label_.sample(n_to_drop).index\n",
    "    df = df.drop(index_to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_some_labels(df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of total samples in dataset and their distribution:  (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64), array([4132, 4684, 2785, 4351, 4072, 3795, 4137, 4401, 4063, 4188],\n",
      "      dtype=int64))\n",
      "\n",
      "Reward for each class.\n",
      "\t- Class 0 : 0.301741\n",
      "\t- Class 1 : 0.266182\n",
      "\t- Class 2 : 0.447682\n",
      "\t- Class 3 : 0.286554\n",
      "\t- Class 4 : 0.306187\n",
      "\t- Class 5 : 0.328536\n",
      "\t- Class 6 : 0.301376\n",
      "\t- Class 7 : 0.283298\n",
      "\t- Class 8 : 0.306865\n",
      "\t- Class 9 : 0.297706\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomImageDataset(df.drop(columns=[\"label\"]), df[\"label\"], (28, 28), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of total samples in dataset and their distribution:  (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64), array([4132, 4684, 2785, 4351, 4072, 3795, 4137, 4401, 4063, 4188],\n",
      "      dtype=int64))\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "network = DQNetwork(state_size=(28, 28, 3), action_size=len(dataset.get_class_num()), gamma = 0.95, epsilon = 1.0, learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of total samples in dataset and their distribution:  (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64), array([4132, 4684, 2785, 4351, 4072, 3795, 4137, 4401, 4063, 4188],\n",
      "      dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(network, dataset, state_size=(28, 28, 3), action_size = len(dataset.get_class_num()), memory=deque(maxlen=2000), epsilon=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_ParallelMapDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hassa\\OneDrive\\Desktop\\AI Degree\\Knowledge Representation and Reasonins\\Deep-Reinforcement-Learning-on-Imbalanced-Data\\DQN\\agent.py:75\u001b[0m, in \u001b[0;36mDQNAgent.train\u001b[1;34m(self, num_episodes)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_episodes):\n\u001b[0;32m     74\u001b[0m     int_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtraining_data))\n\u001b[1;32m---> 75\u001b[0m     state_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtraining_data[int_val]\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m state, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(state_batch):\n\u001b[0;32m     77\u001b[0m         action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(state)\n",
      "\u001b[1;31mTypeError\u001b[0m: '_ParallelMapDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "agent.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
